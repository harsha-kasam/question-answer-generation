{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEFPhsMahe2A"
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfORgTC5he2E"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from -r Requirements.txt (line 1)) (1.5.2)\n",
      "Requirement already satisfied: spacy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from -r Requirements.txt (line 2)) (3.4.4)\n",
      "Requirement already satisfied: tqdm in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from -r Requirements.txt (line 3)) (4.64.1)\n",
      "Requirement already satisfied: python-time in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from -r Requirements.txt (line 4)) (0.3.0)\n",
      "Requirement already satisfied: pickle5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from -r Requirements.txt (line 5)) (0.0.11)\n",
      "Requirement already satisfied: pathlib in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from -r Requirements.txt (line 6)) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas->-r Requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas->-r Requirements.txt (line 1)) (1.23.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas->-r Requirements.txt (line 1)) (2022.7)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy->-r Requirements.txt (line 2)) (6.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy->-r Requirements.txt (line 2)) (21.3)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy->-r Requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: setuptools in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy->-r Requirements.txt (line 2)) (65.5.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy->-r Requirements.txt (line 2)) (3.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy->-r Requirements.txt (line 2)) (3.0.10)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy->-r Requirements.txt (line 2)) (2.0.8)\n",
      "Requirement already satisfied: jinja2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy->-r Requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy->-r Requirements.txt (line 2)) (2.0.7)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy->-r Requirements.txt (line 2)) (8.1.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy->-r Requirements.txt (line 2)) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy->-r Requirements.txt (line 2)) (2.4.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy->-r Requirements.txt (line 2)) (1.10.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy->-r Requirements.txt (line 2)) (0.10.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy->-r Requirements.txt (line 2)) (1.0.9)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy->-r Requirements.txt (line 2)) (2.28.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy->-r Requirements.txt (line 2)) (3.0.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy->-r Requirements.txt (line 2)) (1.0.4)\n",
      "Requirement already satisfied: arrow in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from python-time->-r Requirements.txt (line 4)) (1.2.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from packaging>=20.0->spacy->-r Requirements.txt (line 2)) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy->-r Requirements.txt (line 2)) (4.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->-r Requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy->-r Requirements.txt (line 2)) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy->-r Requirements.txt (line 2)) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy->-r Requirements.txt (line 2)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy->-r Requirements.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy->-r Requirements.txt (line 2)) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy->-r Requirements.txt (line 2)) (0.0.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy->-r Requirements.txt (line 2)) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from jinja2->spacy->-r Requirements.txt (line 2)) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r Requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "a2fO15w8he2F"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fsg5Izi6he2G"
   },
   "source": [
    "### Spacy\n",
    "For the features of the words we're going to use spacy. Once we tokenize the text, we can access features like Part of speech and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.4.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.8 MB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from en-core-web-sm==3.4.1) (3.4.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.9)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (6.3.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: setuptools in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (65.5.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.23.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.10.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.28.1)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.64.1)\n",
      "Requirement already satisfied: jinja2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.1.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (21.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.10)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.8)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_sm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AtERKw4Nhe2G",
    "outputId": "ac3538f4-3205-4701-8042-a285872e6943"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twf9HFxrhe2H"
   },
   "source": [
    "#### Displaying progress\n",
    "tqdm is a progress bar. It will come usefeful when we extract the answers for all the articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "svXt9cKOhe2H"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "60APl_Euhe2H",
    "outputId": "73222a58-c543-4353-9d61-b4378641b0ad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.99it/s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for i in tqdm(range(10)):\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N6e8JqGhhe2J"
   },
   "source": [
    "#### Pickling\n",
    "Once we extract all the words from the texts, we'll save them using pickle. Then we can easily use them in the other modules and have to wait for them to generat again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3bMtQ8tphe2J"
   },
   "outputs": [],
   "source": [
    "import _pickle as cPickle\n",
    "from pathlib import Path\n",
    "\n",
    "def dumpPickle(fileName, content):\n",
    "    pickleFile = open(fileName, 'wb')\n",
    "    cPickle.dump(content, pickleFile, -1)\n",
    "    pickleFile.close()\n",
    "\n",
    "def loadPickle(fileName):    \n",
    "    file = open(fileName, 'rb')\n",
    "    content = cPickle.load(file)\n",
    "    file.close()\n",
    "    \n",
    "    return content\n",
    "    \n",
    "def pickleExists(fileName):\n",
    "    file = Path(fileName)\n",
    "    \n",
    "    if file.is_file():\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfJreAyqhe2J"
   },
   "source": [
    "## Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "eRgtSNUYhe2K"
   },
   "outputs": [],
   "source": [
    "train = pd.read_json('../data/squad-v1/train-v1.1.json', orient='column')\n",
    "dev = pd.read_json('../data/squad-v1/dev-v1.1.json', orient='column')\n",
    "\n",
    "df = pd.concat([train, dev], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "r6AOPjNvhe2K",
    "outputId": "52b11ced-9516-48ed-c838-7c66ce859add"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'title': 'University_of_Notre_Dame', 'paragra...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'title': 'Beyoncé', 'paragraphs': [{'context'...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'title': 'Montana', 'paragraphs': [{'context'...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'title': 'Genocide', 'paragraphs': [{'context...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'title': 'Antibiotics', 'paragraphs': [{'cont...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  version\n",
       "0  {'title': 'University_of_Notre_Dame', 'paragra...      1.1\n",
       "1  {'title': 'Beyoncé', 'paragraphs': [{'context'...      1.1\n",
       "2  {'title': 'Montana', 'paragraphs': [{'context'...      1.1\n",
       "3  {'title': 'Genocide', 'paragraphs': [{'context...      1.1\n",
       "4  {'title': 'Antibiotics', 'paragraphs': [{'cont...      1.1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w67nwaY_he2K"
   },
   "source": [
    "## Extracting words from a paragrapgh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "CWpf3zzuhe2K"
   },
   "outputs": [],
   "source": [
    "currText = df['data'][0]['paragraphs'][0]['context']\n",
    "currQas = df['data'][0]['paragraphs'][0]['qas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-YUr7_BShe2L"
   },
   "outputs": [],
   "source": [
    "currDoc = nlp(currText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "DwI6it0she2L"
   },
   "outputs": [],
   "source": [
    "#Extract answers and the sentence they are in\n",
    "def extractAnswers(qas, doc):\n",
    "    answers = []\n",
    "\n",
    "    senStart = 0\n",
    "    senId = 0\n",
    "\n",
    "    for sentence in doc.sents:\n",
    "        senLen = len(sentence.text)\n",
    "\n",
    "        for answer in qas:\n",
    "            answerStart = answer['answers'][0]['answer_start']\n",
    "\n",
    "            if (answerStart >= senStart and answerStart < (senStart + senLen)):\n",
    "                answers.append({'sentenceId': senId, 'text': answer['answers'][0]['text']})\n",
    "\n",
    "        senStart += senLen\n",
    "        senId += 1\n",
    "    \n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tbxQMf2nhe2L",
    "outputId": "d55a1390-17fa-41c1-c358-6ecea193fcd5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sentenceId': 1, 'text': 'a golden statue of the Virgin Mary'},\n",
       " {'sentenceId': 2, 'text': 'a copper statue of Christ'},\n",
       " {'sentenceId': 3, 'text': 'the Main Building'},\n",
       " {'sentenceId': 4, 'text': 'a Marian place of prayer and reflection'},\n",
       " {'sentenceId': 5, 'text': 'Saint Bernadette Soubirous'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currAnswers = extractAnswers(currQas, currDoc)\n",
    "currAnswers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "se9EAHSghe2L"
   },
   "outputs": [],
   "source": [
    "#TODO - Clean answers from stopwords?\n",
    "def tokenIsAnswer(token, sentenceId, answers):\n",
    "    for i in range(len(answers)):\n",
    "        if (answers[i]['sentenceId'] == sentenceId):\n",
    "            if (answers[i]['text'] == token):\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oqqHiXxFhe2M",
    "outputId": "f73e6d65-0c1e-4f3c-84f3-73fed1d7bbe6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenIsAnswer('the Main Building', 4, currAnswers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "_7QXQotthe2M"
   },
   "outputs": [],
   "source": [
    "#Save named entities start points\n",
    "\n",
    "def getNEStartIndexs(doc):\n",
    "    neStarts = {}\n",
    "    for ne in doc.ents:\n",
    "        neStarts[ne.start] = ne\n",
    "        \n",
    "    return neStarts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TED9tzj9he2M",
    "outputId": "d74fabd3-86ad-40f5-d5ff-2007c0c2fa1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORP\n"
     ]
    }
   ],
   "source": [
    "currNeStarts = getNEStartIndexs(currDoc)\n",
    "\n",
    "if 6 in currNeStarts:\n",
    "    print(currNeStarts[6].label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "3wgcLLeOhe2M"
   },
   "outputs": [],
   "source": [
    "def getSentenceStartIndexes(doc):\n",
    "    senStarts = []\n",
    "    \n",
    "    for sentence in doc.sents:\n",
    "        senStarts.append(sentence[0].i)\n",
    "    \n",
    "    return senStarts\n",
    "    \n",
    "def getSentenceForWordPosition(wordPos, senStarts):\n",
    "    for i in range(1, len(senStarts)):\n",
    "        if (wordPos < senStarts[i]):\n",
    "            return i - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y3J79wAvhe2M",
    "outputId": "bfbd1aa5-7fc1-42a2-aae5-d85f5a756930"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 9, 25, 55, 68, 84, 108]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senStarts = getSentenceStartIndexes(currDoc)\n",
    "senStarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "hgUGMfTahe2M"
   },
   "outputs": [],
   "source": [
    "getSentenceForWordPosition(108, senStarts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "id": "c6Cs7OUMhe2M",
    "outputId": "e863e71d-32ac-4d31-a88a-b1a83747f3ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>isAnswer</th>\n",
       "      <th>titleId</th>\n",
       "      <th>paragrapghId</th>\n",
       "      <th>sentenceId</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>NER</th>\n",
       "      <th>POS</th>\n",
       "      <th>TAG</th>\n",
       "      <th>DEP</th>\n",
       "      <th>shape</th>\n",
       "      <th>Rake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, isAnswer, titleId, paragrapghId, sentenceId, wordCount, NER, POS, TAG, DEP, shape, Rake]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the dataframe\n",
    "wordColums = ['text', 'isAnswer', 'titleId', 'paragrapghId', 'sentenceId','wordCount', 'NER', 'POS', 'TAG', 'DEP','shape', 'Rake']\n",
    "wordDf = pd.DataFrame(columns=wordColums)\n",
    "\n",
    "#Save to pickle\n",
    "\n",
    "#load df\n",
    "\n",
    "#Add new words to array\n",
    "newWord = ['koala', True, 0, 0, 4, 1, None, None, None, None, 'xxxxx']\n",
    "newWords = []\n",
    "#newWords.append(newWord)\n",
    "\n",
    "#Make array to dataframe\n",
    "newWordsDf = pd.DataFrame(newWords, columns=wordColums)\n",
    "newWordsDf\n",
    "\n",
    "#Merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cYJgALWulXCP",
    "outputId": "f82d1ee6-79a4-4884-e38c-3e06387615ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rake_nltk in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.0.6)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from rake_nltk) (3.8)\n",
      "Requirement already satisfied: tqdm in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (2022.10.31)\n",
      "Requirement already satisfied: joblib in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (1.2.0)\n",
      "Requirement already satisfied: click in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (8.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install rake_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5APSMbT0hlyv",
    "outputId": "95217756-86d4-425e-a59b-1bf4bebe1841"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/studio-lab-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/studio-lab-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rake_nltk import Rake\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "_YKw9nXjhe2N"
   },
   "outputs": [],
   "source": [
    "# from keybert import KeyBERT\n",
    "\n",
    "def addWordsForParagrapgh(newWords, titleId, paragraphId):\n",
    "    text = df['data'][titleId]['paragraphs'][paragraphId]['context']\n",
    "    qas = df['data'][titleId]['paragraphs'][paragraphId]['qas']\n",
    "\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    r = Rake()\n",
    "    r.extract_keywords_from_text(text)\n",
    "    b = r.get_ranked_phrases()\n",
    "    \n",
    "    # kb_model = KeyBERT()\n",
    "    # keywords = kb_model.extract_keywords(text)\n",
    "    \n",
    "    answers = extractAnswers(qas, doc)\n",
    "    neStarts = getNEStartIndexs(doc)\n",
    "    senStarts = getSentenceStartIndexes(doc)\n",
    "    \n",
    "    #index of word in spacy doc text\n",
    "    i = 0\n",
    "    \n",
    "    while (i < len(doc)):\n",
    "        #If the token is a start of a Named Entity, add it and push to index to end of the NE\n",
    "        if (i in neStarts):\n",
    "            word = neStarts[i]\n",
    "            #add word\n",
    "            currentSentence = getSentenceForWordPosition(word.start, senStarts)\n",
    "            wordLen = word.end - word.start\n",
    "            shape = ''\n",
    "            for wordIndex in range(word.start, word.end):\n",
    "                shape += (' ' + doc[wordIndex].shape_)\n",
    "\n",
    "            newWords.append([word.text,\n",
    "                            tokenIsAnswer(word.text, currentSentence, answers),\n",
    "                            titleId,\n",
    "                            paragraphId,\n",
    "                            currentSentence,\n",
    "                            wordLen,\n",
    "                            word.label_,\n",
    "                            None,\n",
    "                            None,\n",
    "                            None,\n",
    "                            shape,\n",
    "                            b.count(word.text)>0])\n",
    "                            # keywords.count(word.text)>0])\n",
    "            i = neStarts[i].end - 1\n",
    "        #If not a NE, add the word if it's not a stopword or a non-alpha (not regular letters)\n",
    "        else:\n",
    "            if (doc[i].is_stop == False and doc[i].is_alpha == True):\n",
    "                word = doc[i]\n",
    "\n",
    "                currentSentence = getSentenceForWordPosition(i, senStarts)\n",
    "                wordLen = 1\n",
    "\n",
    "                newWords.append([word.text,\n",
    "                                tokenIsAnswer(word.text, currentSentence, answers),\n",
    "                                titleId,\n",
    "                                paragraphId,\n",
    "                                currentSentence,\n",
    "                                wordLen,\n",
    "                                None,\n",
    "                                word.pos_,\n",
    "                                word.tag_,\n",
    "                                word.dep_,\n",
    "                                word.shape_,\n",
    "                                b.count(word.text)>0])\n",
    "                                # keywords.count(word.text)>0])\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "058EW9QChe2N"
   },
   "outputs": [],
   "source": [
    "#TODO For each token add, for each NE add... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "M7VkAFvvhe2N"
   },
   "outputs": [],
   "source": [
    "newWords = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ZmL-pl8Qhe2N"
   },
   "outputs": [],
   "source": [
    "addWordsForParagrapgh(newWords, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iMdpe2j-he2N",
    "outputId": "e53fd48b-ae2c-46b4-bf3d-5212fe588f3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['universities', False, 0, 1, 0, 1, None, 'NOUN', 'NNS', 'pobj', 'xxxx', True]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newWords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "X3lCIpDlhe2O",
    "outputId": "a4397db6-229f-4d72-96ab-2f173c5bd1cc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>isAnswer</th>\n",
       "      <th>titleId</th>\n",
       "      <th>paragrapghId</th>\n",
       "      <th>sentenceId</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>NER</th>\n",
       "      <th>POS</th>\n",
       "      <th>TAG</th>\n",
       "      <th>DEP</th>\n",
       "      <th>shape</th>\n",
       "      <th>Rake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>universities</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>pobj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Notre Dame's</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>ORG</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Xxxxx Xxxx 'x</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>students</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>run</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBP</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>xxx</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>number</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>dobj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text  isAnswer  titleId  paragrapghId  sentenceId  wordCount   NER  \\\n",
       "0  universities     False        0             1         0.0          1  None   \n",
       "1  Notre Dame's     False        0             1         0.0          3   ORG   \n",
       "2      students     False        0             1         0.0          1  None   \n",
       "3           run     False        0             1         0.0          1  None   \n",
       "4        number     False        0             1         0.0          1  None   \n",
       "\n",
       "    POS   TAG    DEP           shape   Rake  \n",
       "0  NOUN   NNS   pobj            xxxx   True  \n",
       "1  None  None   None   Xxxxx Xxxx 'x  False  \n",
       "2  NOUN   NNS  nsubj            xxxx   True  \n",
       "3  VERB   VBP   ROOT             xxx  False  \n",
       "4  NOUN    NN   dobj            xxxx   True  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newWordsDf = pd.DataFrame(newWords, columns=wordColums)\n",
    "newWordsDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "4nv4y3ZNhe2O",
    "outputId": "4a0b194f-9048-4891-ff4a-b0b26b8b3823"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>isAnswer</th>\n",
       "      <th>titleId</th>\n",
       "      <th>paragrapghId</th>\n",
       "      <th>sentenceId</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>NER</th>\n",
       "      <th>POS</th>\n",
       "      <th>TAG</th>\n",
       "      <th>DEP</th>\n",
       "      <th>shape</th>\n",
       "      <th>Rake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>three</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>September 1876</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>DATE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Xxxxx dddd</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1987</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DATE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>dddd</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              text  isAnswer  titleId  paragrapghId  sentenceId  wordCount  \\\n",
       "13           three      True        0             1         1.0          1   \n",
       "24  September 1876      True        0             1         2.0          2   \n",
       "75            1987      True        0             1         7.0          1   \n",
       "\n",
       "         NER   POS   TAG   DEP        shape   Rake  \n",
       "13  CARDINAL  None  None  None         xxxx   True  \n",
       "24      DATE  None  None  None   Xxxxx dddd  False  \n",
       "75      DATE  None  None  None         dddd   True  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newWordsDf[newWordsDf['isAnswer'] == True].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NkvXlufhe2O"
   },
   "source": [
    "Generating a words for 2 titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uPQAqTNGhe2O",
    "outputId": "4ad22bbb-8de9-4483-f4f6-cd063dca7c81"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:05<00:00,  2.70s/it]\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "\n",
    "#titlesCount = len(df['data'])\n",
    "titlesCount = 2\n",
    "\n",
    "for titleId in tqdm(range(titlesCount)):\n",
    "    paragraphsCount = len(df['data'][titleId]['paragraphs'])\n",
    "        \n",
    "    for paragraphId in range(paragraphsCount):\n",
    "        addWordsForParagrapgh(words, titleId, paragraphId)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4nWmjcNehe2O",
    "outputId": "e74bfa92-0e33-456a-a454-d2da3f582f85"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>isAnswer</th>\n",
       "      <th>titleId</th>\n",
       "      <th>paragrapghId</th>\n",
       "      <th>sentenceId</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>NER</th>\n",
       "      <th>POS</th>\n",
       "      <th>TAG</th>\n",
       "      <th>DEP</th>\n",
       "      <th>shape</th>\n",
       "      <th>Rake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Architecturally</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>ORG</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>school</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Catholic</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NORP</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>character</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>dobj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Atop</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>Xxxx</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              text  isAnswer  titleId  paragrapghId  sentenceId  wordCount  \\\n",
       "0  Architecturally     False        0             0         0.0          1   \n",
       "1           school     False        0             0         0.0          1   \n",
       "2         Catholic     False        0             0         0.0          1   \n",
       "3        character     False        0             0         0.0          1   \n",
       "4             Atop     False        0             0         1.0          1   \n",
       "\n",
       "    NER   POS   TAG    DEP   shape   Rake  \n",
       "0   ORG  None  None   None   Xxxxx  False  \n",
       "1  None  NOUN    NN  nsubj    xxxx   True  \n",
       "2  NORP  None  None   None   Xxxxx  False  \n",
       "3  None  NOUN    NN   dobj    xxxx  False  \n",
       "4  None   ADP    IN   prep    Xxxx  False  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsDf = pd.DataFrame(words, columns=wordColums)\n",
    "wordsDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uoYAWKkXhe2O",
    "outputId": "bc63a5dc-53b9-41ea-ff57-a27c82ae9f9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words for 2 articles: 8664\n"
     ]
    }
   ],
   "source": [
    "print(\"Total words for 2 articles:\", len(wordsDf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mc3aXJjxhe2O"
   },
   "source": [
    "## Generating the entire word dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2fdoADaMhe2P",
    "outputId": "c3e983ac-ae20-413a-939b-d3660af4e61f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:02<00:02,  2.76s/it]"
     ]
    }
   ],
   "source": [
    "wordPickleName = '../data/pickles/wordsDf.pkl'\n",
    "# wordPickleName = '/content/wordsDf.pkl'\n",
    "#If the dataframe is already generated, load it.\n",
    "if (pickleExists(wordPickleName)):\n",
    "    print(\"Pickle found. Saved some time.\")\n",
    "    wordsDf = loadPickle(wordPickleName)\n",
    "else:\n",
    "    #Extracting words\n",
    "    words = []\n",
    "\n",
    "#     titlesCount = len(df['data'])   \n",
    "    titlesCount = 2   \n",
    "\n",
    "    for titleId in tqdm(range(titlesCount)):\n",
    "        paragraphsCount = len(df['data'][titleId]['paragraphs'])\n",
    "\n",
    "#         printProgress(titleId, titlesCount - 1)\n",
    "\n",
    "        for paragraphId in range(paragraphsCount):\n",
    "            addWordsForParagrapgh(words, titleId, paragraphId)\n",
    "    \n",
    "    #Create the dataframe\n",
    "    wordColums = ['text', 'isAnswer', 'titleId', 'paragrapghId', 'sentenceId','wordCount', 'NER', 'POS', 'TAG', 'DEP','shape', 'Rake']\n",
    "    wordsDf = pd.DataFrame(words, columns=wordColums)\n",
    "    \n",
    "    #Pickle the result\n",
    "    dumpPickle(wordPickleName, wordsDf)\n",
    "    print(\"Result was not pickled. You had to wait.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjH-XBq6he2P"
   },
   "source": [
    "Total extracted words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_nNq8AWJhe2P",
    "outputId": "0f52f432-3659-4ca0-8d21-b34b2d0ae0df"
   },
   "outputs": [],
   "source": [
    "print(\"Total words for all articles:\", len(wordsDf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSxacq7Ohe2P"
   },
   "source": [
    "Check what percentage of the extracted words are answers in the dataframe. They should be pretty low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t7xM7fwJhe2P",
    "outputId": "1fae63f5-3e51-4920-f93a-1b6509ad2d43"
   },
   "outputs": [],
   "source": [
    "totalAnswers = len(wordsDf[wordsDf['isAnswer'] == True])\n",
    "print(totalAnswers, 'total answers', '{:.2f}%'.format((totalAnswers / len(wordsDf)) * 100), 'of all words are answers.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r-rtZ8F_he2P"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
